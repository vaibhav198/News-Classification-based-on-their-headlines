{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/vs/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#Importing Libraries\n",
    "import copy\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading of data\n",
    "titles = []\n",
    "categories = []\n",
    "with open('dsjVoxArticles.tsv','r') as tsv:\n",
    "    count = 0;\n",
    "\n",
    "    for line in tsv:\n",
    "        a = line.strip().split('\\t')[:3]\n",
    "        if a[2] in ['Business & Finance', 'Health Care', 'Science & Health', 'Politics & Policy', 'Criminal Justice']:\n",
    "            title = a[0].lower()\n",
    "            title = re.sub('\\s\\W',' ',title)\n",
    "            title = re.sub('\\W\\s',' ',title)\n",
    "            titles.append(title)\n",
    "            categories.append(a[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:  1779\n",
      "Developement:  594\n",
      "Testing:  792\n"
     ]
    }
   ],
   "source": [
    "#Now spliting the data \n",
    "\n",
    "title_tr, title_te, category_tr, category_te = train_test_split(titles,categories)\n",
    "title_tr, title_de, category_tr, category_de = train_test_split(title_tr,category_tr)\n",
    "print(\"Training: \",len(title_tr))\n",
    "print(\"Developement: \",len(title_de),)\n",
    "print(\"Testing: \",len(title_te))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorize the data using Bag of words (BOW)\n",
    "\n",
    "tokenizer = nltk.tokenize.RegexpTokenizer(r\"\\w+\")\n",
    "stop_words = nltk.corpus.stopwords.words(\"english\")\n",
    "vectorizer = CountVectorizer(tokenizer=tokenizer.tokenize, stop_words=stop_words)\n",
    "\n",
    "vectorizer.fit(iter(title_tr))\n",
    "Xtr = vectorizer.transform(iter(title_tr))\n",
    "Xde = vectorizer.transform(iter(title_de))\n",
    "Xte = vectorizer.transform(iter(title_te))\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(category_tr)\n",
    "Ytr = encoder.transform(category_tr)\n",
    "Yde = encoder.transform(category_de)\n",
    "Yte = encoder.transform(category_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features before reduction :  4270\n",
      "Number of features after reduction :  1790\n"
     ]
    }
   ],
   "source": [
    "#Feature Reduction\n",
    "# We can check the variance of the feature and drop them based on a threshold\n",
    "print(\"Number of features before reduction : \", Xtr.shape[1])\n",
    "selection = VarianceThreshold(threshold=0.001)\n",
    "Xtr_whole = copy.deepcopy(Xtr)\n",
    "Ytr_whole = copy.deepcopy(Ytr)\n",
    "selection.fit(Xtr)\n",
    "Xtr = selection.transform(Xtr)\n",
    "Xde = selection.transform(Xde)\n",
    "Xte = selection.transform(Xte)\n",
    "print(\"Number of features after reduction : \", Xtr.shape[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    precision    recall  f1-score   support\n",
      "\n",
      "Business & Finance       0.58      0.34      0.43        87\n",
      "  Criminal Justice       0.71      0.45      0.55        82\n",
      "       Health Care       0.65      0.49      0.56        67\n",
      " Politics & Policy       0.57      0.77      0.66       230\n",
      "  Science & Health       0.64      0.64      0.64       128\n",
      "\n",
      "         micro avg       0.61      0.61      0.61       594\n",
      "         macro avg       0.63      0.54      0.57       594\n",
      "      weighted avg       0.62      0.61      0.60       594\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nb = MultinomialNB()\n",
    "nb.fit(Xtr, Ytr)\n",
    "pred_nb = nb.predict(Xde)\n",
    "print(classification_report(Yde, pred_nb, target_names=encoder.classes_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    precision    recall  f1-score   support\n",
      "\n",
      "Business & Finance       0.63      0.38      0.47       108\n",
      "  Criminal Justice       0.70      0.51      0.59       100\n",
      "       Health Care       0.51      0.42      0.46        72\n",
      " Politics & Policy       0.64      0.80      0.71       353\n",
      "  Science & Health       0.69      0.65      0.67       159\n",
      "\n",
      "         micro avg       0.64      0.64      0.64       792\n",
      "         macro avg       0.63      0.55      0.58       792\n",
      "      weighted avg       0.64      0.64      0.63       792\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Predicting test data using Multinomial Naive Bayesian\n",
    "pred_final = nb.predict(Xte)\n",
    "print(classification_report(Yte, pred_final, target_names=encoder.classes_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
